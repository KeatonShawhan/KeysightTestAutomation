---
- name: Run “9 AM Monday” scenario on all farmslug Pis
  hosts: all
  gather_facts: no
  vars:
    # must be passed with --extra-vars or defaults below apply
    runners: 3
    test_plan: /home/pi/Baseline.TapPlan
    reg_token: CHANGE_ME
    repo_dir: ~/KeysightTestAutomation
    script: test-scripts/9am_monday.sh
  tasks:

  - name: Set a single dump folder for this run (controller fact)
    delegate_to: localhost
    run_once: true
    set_fact:
      # one timestamp for the whole playbook
      ctl_metrics_dir: "/tmp/metrics_dump/{{ lookup('pipe', 'date +%Y%m%d_%H%M%S') }}"

  - name: Ensure controller-side dump folder exists
    delegate_to: localhost
    run_once: true
    file:
      path: "{{ ctl_metrics_dir }}"
      state: directory
      mode: "0755"

  - name: Ensure repo is up-to-date (git stash + pull)
    ansible.builtin.shell: git -C {{ repo_dir}} stash --quiet && git -C {{ repo_dir }} pull --rebase --quiet
    changed_when: false

  - name: Run the 9 AM Monday script
    ansible.builtin.shell: |
      cd {{ repo_dir }}
      chmod +x {{ script }}
      ./{{ script }} {{ runners }} {{ test_plan }} {{ reg_token }}
    async: 7200          # run up to 2 hours without blocking forks
    poll: 0
    register: job

  - name: Wait for script to finish
    ansible.builtin.async_status:
      jid: "{{ job.ansible_job_id }}"
    register: job_status
    until: job_status.finished
    retries: 720           # check every 10 s ⇒ 2 hours max
    delay: 10
  # ------------------------------------------------------------------
  # Pull a host-level summary from the newest metrics folder
  # ------------------------------------------------------------------

  - name: Compute per-host summary (fastest / slowest / avg runtime)
    ansible.builtin.shell: |
      metrics_root="$HOME/KeysightTestAutomation/metrics"
      latest="$(ls -1td "$metrics_root"/* 2>/dev/null | head -1)"
      if [ -z "$latest" ]; then
        printf "0,0,0" && exit 0
      fi
      awk -F',' '/runtime=/{split($0,a,"runtime="); sum+=a[2]; c++; \
                   if(min==""||a[2]<min){min=a[2]} \
                   if(a[2]>max){max=a[2]}} \
                   END{printf "%s,%s,%s", min,max,(c?sum/c:0)}' \
          "$latest"/*_metrics.log
    register: host_summary
    changed_when: false

  - name: Save numbers as a fact on THIS host
    ansible.builtin.set_fact:
      script_runtimes:
        fastest: "{{ host_summary.stdout.split(',')[0] | float }}"
        slowest: "{{ host_summary.stdout.split(',')[1] | float }}"
        average: "{{ host_summary.stdout.split(',')[2] | float }}"

  # ------------------------------------------------------------------
  # Just echo what this host stored (one line per host)
  # ------------------------------------------------------------------
  - name: Show raw summary_parsed on this host
    debug:
      var: script_runtimes

  # ------------------------------------------------------------------
  # Copy resource-usage log to controller
  # ------------------------------------------------------------------
  - name: Find newest 9amMonday metrics folder
    ansible.builtin.shell: |
      ls -1td "$HOME/KeysightTestAutomation/metrics"/9amMonday_* 2>/dev/null | head -1
    register: latest_run_dir
    changed_when: false

  - name: Stat resource_usage.log
    ansible.builtin.stat:
      path: "{{ latest_run_dir.stdout }}/resource_usage.log"
    register: res_log

  - name: Fetch resource_usage.log to controller (if present)
    ansible.builtin.fetch:
      src:  "{{ latest_run_dir.stdout }}/resource_usage.log"
      dest: "{{ ctl_metrics_dir }}/{{ inventory_hostname }}_resource_usage.log"
      flat: true
    when: res_log.stat.exists

  - name: Pop previously stashed git changes 
    ansible.builtin.shell: git -C {{ repo_dir}} stash pop --quiet
    changed_when: false

# ------------------------------------------------------------------
# Controller-only: merge all fetched logs ➜ Influx line protocol
# ------------------------------------------------------------------
- name: Build InfluxDB dump from resource logs
  hosts: localhost
  gather_facts: no
  vars:
    # reuse the path that the first play stored on localhost
    ctl_metrics_dir: "{{ hostvars.localhost.ctl_metrics_dir }}"
    dump_file: "{{ ctl_metrics_dir }}/influxdump_{{ lookup('pipe','date +%Y%m%d_%H%M%S') }}.lp"
  tasks:
    - name: Convert each *_resource_usage.log into Influx line protocol
      shell: |
        outfile="{{ dump_file }}"
        : > "$outfile"
        shopt -s nullglob
        for f in "{{ ctl_metrics_dir }}"/*_resource_usage.log; do
          host="${f%%_*}"                 # strip “_resource_usage.log”
          host="${host##*/}"              # strip any leading path
          awk -F',' -v host="$host" 'NR>1{
              ts_ns = $1 "000000000";
              cpu=$2; mem=$3;
              rd=($4==""?0:$4); wr=($5==""?0:$5);
              rx=($6==""?0:$6); tx=($7==""?0:$7);
              load=$8;
              printf "pi_resources,host=%s cpu_percent=%s,memory_kb=%s,"
              printf "disk_io_read_kb=%s,disk_io_write_kb=%s,"
              printf "network_rx_bytes=%s,network_tx_bytes=%s,load_avg=%s %s\n",
                     host,cpu,mem,rd,wr,rx,tx,load,ts_ns;
          }' "$f" >> "$outfile"
        done
      args:
        executable: /bin/bash
      changed_when: true

    - name: Tell user where the dump file is
      debug:
        msg: "Combined InfluxDB dump written to {{ dump_file }}"
